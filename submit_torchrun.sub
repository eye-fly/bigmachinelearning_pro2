#!/bin/bash
#SBATCH --job-name=torchrun
#SBATCH --time=0:30:00
#SBATCH --partition=plgrid-gpu-a100
#SBATCH --gres=gpu:1
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=4
#SBATCH --mem=32G
#SBATCH --output=logs/output_%j.txt
#SBATCH --error=logs/error_%j.txt

mkdir -p logs

source .venv/bin/activate

export MASTER_ADDR=$(scontrol show hostnames "$SLURM_JOB_NODELIST" | head -n 1)
export MASTER_PORT=29500


torchrun \
    --nnodes=$SLURM_JOB_NUM_NODES \
    --nproc_per_node=1 \
    --rdzv_id=$SLURM_JOB_ID \
    --rdzv_backend=c10d \
    --rdzv_endpoint=$MASTER_ADDR:$MASTER_PORT \
    main.py \
    --n_layers 4 \
    --dmodel 256 \
    --n_heads 4 \
    --batch_size 64 \
    --n_training_steps 1000